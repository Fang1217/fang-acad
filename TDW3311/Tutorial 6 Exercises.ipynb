{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Dealing with Missing Data\n",
    " \n",
    "In this exercise, you need to download `Estate.csv` and import it into Pandas data frame. This is a small data set which contains only 10 rows. There are three different types of missing data: standard missing data (in column `ST_NUM`), non standard missing data (in `NUM_BEDROOMS`), and unexpected missing values (in `OWN_OCCUPIED`). \n",
    "\n",
    "Now, complete the following tasks by using appropriate python code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex1.1:\tImport the relevant libraries, read the data into Pandas data frame and look at the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "import numpy as np\n",
    "data1 = pd.read_csv('Datasets/Estate.csv')\n",
    "#look at the first few rows\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex1.2:\tDealing with the standard missing data - check the number of missing values of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex1.3:\tCheck the value of `NUM_BEDROOM`. Note that, these columns contain non-standard missing values as well. Change all the non-standard missing values to NaN. After that, check the value of `NUM_BEDROOMS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['NUM_BEDROOMS']\n",
    "\n",
    "missing_values=['n.a','na','--']\n",
    "data1=pd.read_csv('Estate.csv',na_values=missing_values)\n",
    "data1['NUM_BEDROOMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex1.4:\tAssume that you found `OWN_OCCUPIED` is having unexpected error. Check the values of this column and observe that it contains data with different data type. Then perform the steps below to change the values that are not the similar type into an integer, and then to `np.nan`\n",
    "\n",
    "Steps: \n",
    "1. Loop through the `OWN_OCCUPIED` column \n",
    "2. Try and turn the entry into an integer \n",
    "3. If the entry can be changed into an integer, enter a missing value \n",
    "4. If the number can’t be an integer, we know it’s a string, so keep going without doing anything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for row in data1['OWN_OCCUPIED']:\n",
    "    try:\n",
    "       int(row)\n",
    "       data1.loc[cnt,'OWN_OCCUPIED']=np.nan\n",
    "    except ValueError:\n",
    "        pass\n",
    "    cnt+=1\n",
    "data1['OWN_OCCUPIED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Dealing with Outliers\n",
    "In this exercise, we will use the Boston housing data. You can download directly from this link here: https://archive.ics.uci.edu/ml/machine-learning-databases/housing/ or import directly from sklearn. This data has no missing values with 506 samples. The attributes information is as below: \n",
    "|   |   |   | \n",
    "|---|---|---|\n",
    "| 1.  | CRIM    | per capita crime rate by town |\n",
    "| 2.  | ZN      | proportion of residential land zoned for lots over 25,000 sq.ft. |\n",
    "| 3.  | INDUS   | proportion of non-retail business acres per town |\n",
    "| 4.  | CHAS    | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "| 5.  | NOX     | nitric oxides concentration (parts per 10 million) |\n",
    "| 6.  | RM      | average number of rooms per dwelling |\n",
    "| 7.  | AGE     | proportion of owner-occupied units built prior to 1940 |\n",
    "| 8.  | DIS     | weighted distances to five Boston employment centres |\n",
    "| 9.  | RAD     | index of accessibility to radial highways |\n",
    "| 10. | TAX     | full-value property-tax rate per $10,000 |\n",
    "| 11. | PTRATIO | pupil-teacher ratio by town |\n",
    "| 12. | B       | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town |\n",
    "| 13. | LSTAT   | % lower status of the population |\n",
    "| 14. | MEDV    | Median value of owner-occupied homes in $1000's |\n",
    "\n",
    "Ex2.1.\tDownload Boston housing data from sklearn.datasets, load the data and save in a Pandas data frame. Remember to import all the necessary files. \n",
    "\n",
    "Ex2.2.\tCheck the features and view the first few rows of the data. \n",
    "\n",
    "Ex2.3.\tVisualize the feature CRIM (per capita crime rate) by using box plot.\n",
    "\n",
    "Ex2.4.\tCheck all the features by using histogram.\n",
    "\n",
    "Ex2.5.\tDefine the z-score of CRIM. \n",
    "\n",
    "Ex2.6.\tRemove those data with z-score (+/-) exceeding 3 standard deviation. How many samples are removed from the data?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Extract South East Asia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mobile cellular subscriptions, total number  1965  1966  1967  1968  1969  \\\n",
      "0                                    Abkhazia   NaN   NaN   NaN   NaN   NaN   \n",
      "1                                 Afghanistan   0.0   NaN   NaN   NaN   NaN   \n",
      "2                       Akrotiri and Dhekelia   NaN   NaN   NaN   NaN   NaN   \n",
      "3                                     Albania   0.0   NaN   NaN   NaN   NaN   \n",
      "4                                     Algeria   0.0   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   1970  1971  1972  1973  ...      2002       2003       2004        2005  \\\n",
      "0   NaN   NaN   NaN   NaN  ...       NaN        NaN        NaN         NaN   \n",
      "1   0.0   NaN   NaN   NaN  ...   25000.0   200000.0   600000.0   1200000.0   \n",
      "2   NaN   NaN   NaN   NaN  ...       NaN        NaN        NaN         NaN   \n",
      "3   0.0   NaN   NaN   NaN  ...  851000.0  1100000.0  1259590.0   1530244.0   \n",
      "4   0.0   NaN   NaN   NaN  ...  450244.0  1446927.0  4882414.0  13661355.0   \n",
      "\n",
      "         2006        2007        2008        2009        2010        2011  \n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "1   2520366.0   4668096.0   7898909.0  10500000.0  13000000.0  17558265.0  \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "3   1909885.0   2322436.0   1859632.0   2463741.0   2692372.0   3100000.0  \n",
      "4  20997954.0  27562721.0  27031472.0  32729824.0  32780165.0  35615926.0  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_excel('Datasets/cell phone total.xlsx', header=[0]) \n",
    "print(data.head())\n",
    "\n",
    "threshold = data.isnull().sum(axis=1)/(len(data.columns)-1) \n",
    "\n",
    "#exclude the 1st column which is the name of countries\n",
    "remove_row = threshold[threshold>0.8].index\n",
    "\n",
    "data.drop(remove_row, axis=0, inplace = True)\n",
    "\n",
    "# Print out all the columns. Suppose the 1st column is not treated as column. Rename the 1st columns as ‘Country’. \n",
    "data.rename(columns={'Mobile cellular subscriptions, total number':'Country'}, inplace = True)\n",
    "\n",
    "# set country as index.\n",
    "data.set_index(\"Country\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex 3.1: Extract South East Asian countries and save as data_asean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asean = data.loc[['Brunei', 'Myanmar', 'Cambodia', 'Indonesia', 'Malaysia', 'Philippines', 'Singapore', 'Thailand', 'Vietnam']]\n",
    "data_asean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex3.2:\tExtract columns 2005 till 2011 from data_asean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asean.loc[:,'2005':'2011']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex3.3:\tSort the results based on year 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asean.loc[:,'2005':'2011'].sort_values(by=['2005'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex3.4:\tExtract Malaysia and Singapore data from year 2010 & 2011 and filter the values to less than 35,000,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asean_sub = data_asean.loc[['Malaysia','Singapore'], ['2010', '2011']]\n",
    "data_asean_sub[(data_asean_sub['2010'] < 35000000) | data_asean_sub['2011'] < 35000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 4: Date Time\n",
    "\n",
    "By referring your lecture notes, \n",
    "- Ex4.1.\tCreate another new column: day_of_week_name where this column stores the day based on the date. For e.g.: 2004-10-03, then day_of_week_name will have the value Sunday.\n",
    "- Ex4.2.\tCalculate the number of years based on current year to the date in data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
